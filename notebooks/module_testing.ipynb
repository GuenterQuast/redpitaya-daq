{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "messung =\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "notebook_path = os.path.abspath('')\n",
    "project_root = os.path.dirname(notebook_path)\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from modules.filters import *\n",
    "\n",
    "from helpers.read_osc_to_df import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Config dict\n",
    "config_dict=yaml.load(open(\"../config/coincidence_config.yaml\", \"r\"),yaml.SafeLoader)[\"find_peaks\"]\n",
    "config_dict\n",
    "\n",
    "# Config from find peaks\n",
    "if config_dict is None:\n",
    "    raise ValueError(\"ERROR! Wrong configuration passed (in lifetime_modules: calculate_decay_time)!!\")\n",
    "\n",
    "# Load configuration\n",
    "sample_time_ns = config_dict[\"sample_time_ns\"]\n",
    "number_of_samples = config_dict[\"number_of_samples\"]\n",
    "analogue_offset = config_dict[\"analogue_offset\"]*1000\n",
    "pre_trigger_samples = config_dict[\"pre_trigger_samples\"]\n",
    "trigger_channel = 'ch'+config_dict[\"trigger_channel\"]\n",
    "coincidence_window = config_dict[\"coincidence_window\"]\n",
    "\n",
    "\n",
    "peak_config = config_dict[\"peak_config\"]\n",
    "\n",
    "\n",
    "list_of_channels = config_dict[\"list_of_channels\"]\n",
    "clipping_level = config_dict[\"clipping_level\"]\n",
    "\n",
    "\n",
    "if trigger_channel not in list_of_channels:\n",
    "    raise ValueError(f'{trigger_channel} not in list of channels: {list_of_channels}') \n",
    "trigger_position_tolerance = config_dict[\"trigger_position_tolerance\"]\n",
    "\n",
    "signal_channels = [channel for channel in list_of_channels if channel != trigger_channel]\n",
    "\n",
    "\n",
    "# nur weil net aus Sink List importierbar\n",
    "pulse_par_dtype = np.dtype([('ch1_position', 'i4'), ('ch1_height', 'f4'), ('ch2_position', 'i4'), ('ch2_height', 'f4')])\n",
    "\n",
    "# glaub neu\n",
    "empty_peak_data=np.zeros( (1,), dtype=pulse_par_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully, recorded triggers = 2752\n"
     ]
    }
   ],
   "source": [
    "#load Data\n",
    "data,number_of_triggers=import_data(project_root+ \"/measurements/measurement_3_\" + messung +\"min.npy\",number_of_samples, list_of_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define tag_pulses\n",
    "def tag_pulses(input_data):   \n",
    "    \"\"\"find all valid pulses \n",
    "\n",
    "    This function to be called by instance of class mimoCoRB.rbTransfer\n",
    "\n",
    "        Args:  input data as structured ndarray\n",
    "\n",
    "        Returns: list of parameterized pulses\n",
    "        \n",
    "        \n",
    "        Currently only works with two channels. Every part which requires two channels ist marked with ### two\n",
    "    \"\"\"\n",
    "    # Find all the peaks and store them in a dictionary\n",
    "    \n",
    "    \n",
    "    #this is ugly :(\n",
    "    #peaks, peaks_prop = tag_peaks(input_data, peak_minimal_prominence, peak_minimal_distance, peak_minimal_width, peak_gradient_bound[\"upper\"],peak_gradient_bound[\"lower\"])\n",
    "    peaks, peaks_prop = tag_peaks(input_data, peak_config)\n",
    "\n",
    "    peak_data=empty_peak_data.copy()\n",
    "    \n",
    "    # Only consider events with one peak in the trigger_channel\n",
    "    if len(peaks[trigger_channel])!=1:\n",
    "        return None\n",
    "    trigger_peak=peaks[trigger_channel][0]\n",
    "    for signal_channel in signal_channels:\n",
    "        if len(peaks[signal_channel])!=1: ### two\n",
    "            return None ### two\n",
    "        Delta_T=coincidence_window[signal_channel]['offest_from_trigger']/sample_time_ns\n",
    "        w=coincidence_window[signal_channel]['width_of_window']/sample_time_ns\n",
    "        for peak in peaks[signal_channel]:\n",
    "            # filter out clipped peaks\n",
    "            if input_data[signal_channel][peak]>=clipping_level:\n",
    "                print('clipped peak')\n",
    "                return None\n",
    "            # check for coincidences\n",
    "            if -w/2<=peak-Delta_T-trigger_peak<=w/2:\n",
    "                found_coincidence=True\n",
    "                # explanation: t+Delta_T-w/2<=peak<=t+Delta_T+w/2\n",
    "                \"\"\"ab hier erstmal nur für einen trigger und einen signal channel\"\"\"\n",
    "                peak_data[0][signal_channel+'_position'] = peak\n",
    "                peak_data[0][trigger_channel+'_position'] = trigger_peak\n",
    "                peak_data[0][signal_channel+'_height'] = peaks_prop[signal_channel]['relative_height'][0] # das muss später weg wenn man mehr als ein peak betrachtet\n",
    "                peak_data[0][trigger_channel+'_height'] = peaks_prop[trigger_channel]['relative_height'][0]\n",
    "    \n",
    "    if peak_data!=empty_peak_data:\n",
    "        print(peak_data)\n",
    "        return peak_data\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(127, 4110., 130, 873.)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot compare structured or void to non-void arrays.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m      2\u001b[0m     t\u001b[38;5;241m=\u001b[39mtag_pulses(d)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m:\n\u001b[0;32m      4\u001b[0m         d_out\u001b[38;5;241m=\u001b[39md\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(d_out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mch1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot compare structured or void to non-void arrays."
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    t=tag_pulses(d)\n",
    "    if t!=None:\n",
    "        d_out=d\n",
    "plt.plot(d_out['ch1'])\n",
    "plt.plot(d_out['ch2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0, 0., 0, 0.)],\n",
       "      dtype=[('ch1_position', '<i4'), ('ch1_height', '<f4'), ('ch2_position', '<i4'), ('ch2_height', '<f4')])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_peak_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
